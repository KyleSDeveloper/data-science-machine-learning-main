{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning to use NLP features and Pipelines\n",
    "\n",
    "Especially pipelines!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer, MinMaxScaler\n",
    "\n",
    "# pipelines\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# NLP transformers\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "# classifiers you can use\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# model selection bits\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score, ShuffleSplit\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, StratifiedKFold, KFold\n",
    "\n",
    "# evaluation\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "# dataset\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# plotting\n",
    "from plotting import plot_learning_curve, plot_validation_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data\n",
    "\n",
    "We are going to be using the 20 News Groups dataset available from [here](http://qwone.com/~jason/20Newsgroups/).  The data is a bunch of news articles, grouped into 20 news groups!\n",
    "\n",
    "Our goal is to classify the documents, into the category it belongs to.  The skills we learn in this assignment will be the following\n",
    "\n",
    "* basics of NLP (tf-idf, n-grams)\n",
    "* how to use pipelines\n",
    "* practice with the scikit-learn dummy model\n",
    "\n",
    "Note that when we load the data we are going to exclude the follow columnts: \"headers\", \"footers\", and \"quotes\" as these are meta-data columns which provide extra information about the news articles.  These features are manually added, so we are removing them since we'd like to try and learn what class an article belongs to using the information present in the article alone.  \n",
    "\n",
    "**NOTE**\n",
    "Due to the way this data is stored, it's actually easier to leave it in it's native format (list and array) from sci-kit learn. So we won't be bothering with pandas here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fetch_20newsgroups(categories = [ 'comp.graphics',\n",
    " 'comp.os.ms-windows.misc',\n",
    " 'comp.sys.ibm.pc.hardware',\n",
    " 'talk.politics.guns',\n",
    " 'talk.politics.mideast',\n",
    " 'talk.religion.misc'],remove=('headers', 'footers', 'quotes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 is comp.graphics\n",
      "1 is comp.os.ms-windows.misc\n",
      "2 is comp.sys.ibm.pc.hardware\n",
      "3 is talk.politics.guns\n",
      "4 is talk.politics.mideast\n",
      "5 is talk.religion.misc\n"
     ]
    }
   ],
   "source": [
    "for i,name in enumerate(data.target_names):\n",
    "    print (f\"{i} is {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have only loaded in two topic types \"computer\" and \"talk\". Furether, I selected only 6 totaltopics from the 20 total that the dataset has to offer. Further we are going to simplify the problem even further, and lump together the two topics into two general topics.  Why?  Because otherwise it takes quite a while to run a single model on this dataset.  After you have built a decent model and tuned it, then you can try loading in more data and attempting to do multi-class classification.  For now we will focus on a simpler binary classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ONLY RUN THIS CELL ONCE ###\n",
    "## RUNNING IT MULTIPLE TIMES WILL BREAK EVERYTHING ### \n",
    "\n",
    "# set the 3 computer targets to one label\n",
    "data.target[data.target == 1] = 0\n",
    "data.target[data.target == 2] = 0\n",
    "\n",
    "# set 3 talk targets to one label\n",
    "data.target[data.target == 3] = 1\n",
    "data.target[data.target == 4] = 1\n",
    "data.target[data.target == 5] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.target_names = [\"computer\",'talk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking that I only have two classes left!\n",
    "np.unique(data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1765, 1487])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's check the distribution of my two classes\n",
    "np.bincount(data.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print a single sample from the news groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I do not think it is at all unlikely that Clinton ro his policy\\nwonk facilitators arranged the Waco raid as a display piece for  the\\nGun War on the Constitution.  Look at what the Bush administration did to\\nget material for the Drug War on the Constitution--remember that baggie of\\ncrack George waved at the cameras?  They took a dealer from the ghetto\\nand brought him to the White House so they could say drugs had been\\ndealt onb the White House Lawn.\\nAnd I don't think anybody could honestly think Clinton would have any\\nmoral qualms about the raid...\\nThe only really worrisome thing is that the BD's heroic defense of\\ntheir ranch will make Clinton's Gun War on the Constitution _more_\\nsuccessfull--exactly as he wanted.  The media and politicians will\\nfilter this so that the general public will think the BD's\\nare bad guys!  Don't help them.  Stand up for the BD's with your\\nfriends and family adnd in public anytime you can--their supposed\\nmoral qualms are not important to the issue.  They are heroes in the\\nfight against oppressive government;  it could just as well have been\\nyou.\\n-watkins@earth.eecs.uic.edu  (Brian E Watkins)\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.data\n",
    "X[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that there are a bunch of weird characters in there, for example I see a bunch of `\\n` character patterns. This is a newline character.  I wonder if we will need to deal with this in any special way when we do our NLP feature extraction?\n",
    "\n",
    "Let's try printing `X[0]` and see if it's different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I do not think it is at all unlikely that Clinton ro his policy\n",
      "wonk facilitators arranged the Waco raid as a display piece for  the\n",
      "Gun War on the Constitution.  Look at what the Bush administration did to\n",
      "get material for the Drug War on the Constitution--remember that baggie of\n",
      "crack George waved at the cameras?  They took a dealer from the ghetto\n",
      "and brought him to the White House so they could say drugs had been\n",
      "dealt onb the White House Lawn.\n",
      "And I don't think anybody could honestly think Clinton would have any\n",
      "moral qualms about the raid...\n",
      "The only really worrisome thing is that the BD's heroic defense of\n",
      "their ranch will make Clinton's Gun War on the Constitution _more_\n",
      "successfull--exactly as he wanted.  The media and politicians will\n",
      "filter this so that the general public will think the BD's\n",
      "are bad guys!  Don't help them.  Stand up for the BD's with your\n",
      "friends and family adnd in public anytime you can--their supposed\n",
      "moral qualms are not important to the issue.  They are heroes in the\n",
      "fight against oppressive government;  it could just as well have been\n",
      "you.\n",
      "-watkins@earth.eecs.uic.edu  (Brian E Watkins)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yup, those `\\n` must be newline characters. They print out fine.  Still I don't think we will want them in our classification model.. or maybe we do? We will have to figure that out.\n",
    "\n",
    "Let's also take a look at the target names -- the category labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['computer', 'talk']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What category do you think that first example belongs to?  Let's check it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'talk'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data.target\n",
    "data.target_names[y[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yup, that seems like an accurate label! It's a \"Talk\" topic.  Ok... now let's build a model and classify these guys!\n",
    "Let's try to follow the basic steps outlined below. Some of them you have seen before, some are new.\n",
    "\n",
    "* split into training / test sets (20% would be a good test set size)\n",
    "* extract features from the training data\n",
    "  * we should use a pipeline for this if we want to do cross validation!\n",
    "* do cross validation on a basic model and see how it performs\n",
    "  * plot learning curves and validation curves on our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training / testing\n",
    "# note I'm setting a random_state, normally I wouldn't but... I want to be able to describe the data to you, and I need to be\n",
    "# sure you have the same split I get.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, test_size = 0.2, random_state=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract features. \n",
    "Ok let's create a CountVectorizer which will create n-grams for us.  You can make a default one if you want (n-grams will be = 1, which is unigrams) or you can specify what length n-grams you want.\n",
    "\n",
    "First we will *fit* the vectorizer. This just \"learns\" all the different n-grams and stores them in a dictionary\n",
    "\n",
    "## A toy example first\n",
    "\n",
    "Let's start with something so small we can get a feeling for it.  We can start with two sentences in a list and we will vectorize those!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;CountVectorizer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\">?<span>Documentation for CountVectorizer</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>CountVectorizer()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toys = [\"this is the first sentence in this list\", \"this is the second sentence\"]\n",
    "test_count = CountVectorizer()\n",
    "test_count.fit(toys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now we have fit our vectorizer.  Let's see what kind of things we can find with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'this': 7,\n",
       " 'is': 2,\n",
       " 'the': 6,\n",
       " 'first': 0,\n",
       " 'sentence': 5,\n",
       " 'in': 1,\n",
       " 'list': 3,\n",
       " 'second': 4}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_count.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this is a unique dictionary of words, each word is mapped to a single integer. It's not a count of the word, it's just an index for it. It's the vocabulary found by the vectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2x8 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 12 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toys_transformed = test_count.transform(toys)\n",
    "toys_transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now we transformed our \"toys\" into a a vectorized format.  It's important that we realize the first step was \"fitting\" the vectorizer, which means it was breaking down the words, finding all the unique unigrams (or whatever amount of grams we asked for) and then putting them into a dictionary.  The next step is to actually _transform_ our dataset into a vector.  What we got back was a sparse array!\n",
    "\n",
    "Sparse arrays are like regular arrays, but they contain mostly zeros so numpy just stores the indices of where the real values actually are.  Lets try to look into ours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 0, 1, 1, 2],\n",
       "       [0, 0, 1, 0, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can transform it into a full array, but you shouldn't really do that....\n",
    "toys_transformed.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t1\n",
      "  (0, 1)\t1\n",
      "  (0, 2)\t1\n",
      "  (0, 3)\t1\n",
      "  (0, 5)\t1\n",
      "  (0, 6)\t1\n",
      "  (0, 7)\t2\n",
      "  (1, 2)\t1\n",
      "  (1, 4)\t1\n",
      "  (1, 5)\t1\n",
      "  (1, 6)\t1\n",
      "  (1, 7)\t1\n"
     ]
    }
   ],
   "source": [
    "print(toys_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the two representations of the array are actually the same.  In the \"regular\" array we get `[1,1,0,1,1]` in the spare array it tells us that (0,0) = 1, (0,1) = 1, (0,3) = 1 ... etc.  That means (0,0) is \"the zeroth row and zeroth column is 1), which is what we see.  Note that the count_vectorizer is _counting_, if a word appeared twice, it's listed as 2. The sparse array only tells us about the _real_ non-zero values.  Scikit-learn is automatically creating a sparse array with the count-vectorizer because it's assuming that most of our arrays will be very sparse.  That is, most of our transformed data will be 0's!  Can you think about why this is true?\n",
    "\n",
    "Ok, let's run this on our actual data now.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;CountVectorizer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\">?<span>Documentation for CountVectorizer</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>CountVectorizer()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count vectorizer, easiest thing to do. Will make n-grams for us.\n",
    "count_vect  = CountVectorizer()\n",
    "count_vect.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50319"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(count_vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got ~50,000 unigrams out of that! Wow.  Let's transfrom our data now and see how sparse it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vect = count_vect.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse._csr.csr_matrix"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2601, 50319)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vect.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so we have a shape of 2601 x 50319\n",
    "That doesn't tell us much about how much a single sample actually has in terms on non-zero elements.  We can check the non-zero elements in two easy ways\n",
    "\n",
    "  1. We can use `.getnnz()` which means \"get non zero\" -- however this tells us the number of non-zero elements, not their sum (not how many times they occured). \n",
    "  2. We can just sum a row with `.sum()` this will tell us how many total elements exist in the array, but we won't know how many are unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    }
   ],
   "source": [
    "print(X_train_vect[0].getnnz())  #getnnz --> \"get non zero\" will tell us how many non-zero entries we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    }
   ],
   "source": [
    "print(X_train_vect[0].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, we see that for the first entry we have only 23 non-zero values in our count matrix.  This means it has 56500 empty values! Now you can see why we use a sparse matrix.  We are in 56,000 dimensions, but with only 23 points! The curse of dimensionality could really hurt us here...\n",
    "\n",
    "# Next step - train our baseline model\n",
    "\n",
    "Use Scikit-Learn's dummy models to make a baseline against. We need to reliably beat this monster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5428681276432141 is the mean score\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.54209919, 0.5432526 , 0.5432526 ])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy = DummyClassifier(strategy='most_frequent')\n",
    "scores = cross_val_score(dummy, X_train, y_train, cv=3, scoring = \"accuracy\") \n",
    "print (f\"{scores.mean()} is the mean score\")\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a real model - with pipelines\n",
    "Now, up until this point we have actually created enough \"features\" that we can train a model. If we run any kind of kfold validation, it would _work_. But it would be very wrong to do that with our current setup.  The thing is, when we perform k-fold validation, we want to simulate testing as if we had a real test set.  Currently we do _not_ have a real test, **because** we have transformed our entire X_train into a count vectorized format.  Let me try to explain the problem.\n",
    "\n",
    "The problem is that the dictionary is learned on the training data and what happens if we see a new word in the validation data, that didn't occur in the testing data? What feature value do we give that? Currently we wouldn't have to worry about that because _all_ samples in training have been converted into vectorized features.\n",
    "\n",
    "But we should have to worry about that!  What if tomorrow we get a new sample of news that contains words we have never seen before? What would we do?  We would need a strategy for dealing with _new never seen before words_. \n",
    "\n",
    "The default behavior of the count-vectorizer is to _ignore_ any new words it has never seen when asked to transform new data.  You can read this [here](https://scikit-learn.org/stable/modules/feature_extraction.html#common-vectorizer-usage).  Note, this is _only one way_ to handle unseen information. There are other strategies, but the point is _you need a strategy_.  \n",
    "\n",
    "If we just run cross-validation right now, with our vectorized X_train, we won't be accounting for this very real problem that _will_ occur with our never before seen testing data. **We need to simulate having words we have _never seen before_.** Therefore we actually need to create the count_vector dictionary and do the transformation for _every fold_ of the cross validation flow.\n",
    "\n",
    "On the first fold, we need to fit a count_vectorizer on 4/5's of the training data and transform it, and then use the same count_vectorizer to transform the held-out validation data.  If it finds words it's never seen before, it will just ignore them.  This will correctly simulate testing data.\n",
    "\n",
    "But how do we setup scikit-learn to automatically fit a transformer on every step of cross-validation!?\n",
    "PIPELINES!\n",
    "\n",
    "With scikit-learn we can setup a pipeline that will do a pre-determined set of steps every single time we call `fit` on it.  It's very easy. Watch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the mean score is: 0.8046751808652001\n",
      "The scores were: [0.84452975 0.775      0.80192308 0.80961538 0.79230769]\n"
     ]
    }
   ],
   "source": [
    "# create the pipeline\n",
    "dt_pipe = Pipeline([('vect', CountVectorizer(ngram_range=(1,1))),('clf', DecisionTreeClassifier())])\n",
    "\n",
    "# pass the pipeline as if it was the classifier into a cross validation method\n",
    "# the cv method will automatically figure out what to do.\n",
    "scores = cross_val_score(dt_pipe, X_train, y_train, cv=5, scoring = 'accuracy')\n",
    "print(f\"the mean score is: {scores.mean()}\")\n",
    "print(\"The scores were:\", scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's break down what I just did.\n",
    "1. I created a pipeline\n",
    "2. I passed the pipeline as if it was the classifier, and everything just worked (during each fold of cross validation, it called `fit_transform` on training with CountVectorizer, followed by `fit` and `predict` with KNN).\n",
    "\n",
    "So how... how does the pipeline work?  Scikit-Learn is very clear about this [here](https://scikit-learn.org/stable/modules/compose.html#pipeline) and [here](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline), the gist is \"All estimators in a pipeline, except the last one, must be transformers (i.e. must have a transform method). The last estimator may be any type (transformer, classifier, etc.).\"\n",
    "\n",
    "CountVectorizer is a transformer, it transforms our data into another format.  We have seen other transformers already (normalizers and standard scalers).  Any object in Scikit-Learn that has a `.transform()` method is a transformer and valid for a pipeline.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting better features\n",
    "\n",
    "Ok, so CountVectorizer at it's basic is just making unigrams.  Can we do better?\n",
    "Well, we have two easy things we can try\n",
    "1. do more than unigrams by setting the option in `CountVectorizer(1,3)` will give us unigrams, bi-grams, and trigrams.\n",
    "2. Use a term-frequency inverse document frequency transformer (TF-IDF).\n",
    "\n",
    "TF-IDF will give a score to each n-gram weighted by the number of times it shows up in the document relevant to the number of times it shows up in the corpus (collection of documents).\n",
    "\n",
    "Let's try a few combinations with DT (which performed OK so far) and see if we can get it better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8027594861951869\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.82533589, 0.80384615, 0.80576923, 0.79807692, 0.78076923])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's make unigrams and bigrams\n",
    "count = CountVectorizer(ngram_range=(1,2))\n",
    "clf = DecisionTreeClassifier()\n",
    "dt_pipe = Pipeline([('vect', count),('clf', clf)])\n",
    "scores = cross_val_score(dt_pipe, X_train, y_train, cv=5, scoring = 'accuracy')\n",
    "print(scores.mean())\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That actually did worse (only marginally)\n",
    "It could very well be because we increased the dimensions even more by adding bigrams? Let's check our new dictionary length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "335645"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(count.fit(X_train).vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, wow, bigrams blew us up from 50k features (dimensions) to 335,000.  That could have affected our scores.  Let's set `max_features` on our vectorizer, this will automatically \"only consider the top max_features ordered by term frequency across the corpus.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.809291303705891\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.84261036, 0.79423077, 0.81923077, 0.80769231, 0.78269231])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's make unigrams and bigrams, we will limit to 65k features\n",
    "count = CountVectorizer(ngram_range=(1,2), max_features=65_000)  #yes you can use _'s in integers!\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "dt_pipe = Pipeline([('vect', count),('clf', clf)])\n",
    "scores = cross_val_score(dt_pipe, X_train, y_train, cv=5, scoring = 'accuracy')\n",
    "print(scores.mean())\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, that didn't really seem to help much.  Let's try going back to unigrams, but adding a TF-IDF vectorizer. Note that the TF-IDF vectorizing takes as it's input a count_matrix, which is exactly what our count-vectorizer builds. So these two items are built to be used together (scikit-learn has a convenence function called tfidf_vectorizer that does both steps automatically)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7950642256016536\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.83301344, 0.79807692, 0.78846154, 0.80576923, 0.75      ])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's make unigrams , we will limit to 10k features\n",
    "count = CountVectorizer(ngram_range=(1,1), max_features=10_000)  #yes you can use _'s in integers!\n",
    "clf = DecisionTreeClassifier()\n",
    "#tf-idf\n",
    "tfidf = TfidfTransformer()\n",
    "\n",
    "dt_pipe = Pipeline([('vect', count),('tfidf',tfidf),('clf', clf)])\n",
    "scores = cross_val_score(dt_pipe, X_train, y_train, cv=5, scoring = 'accuracy')\n",
    "print(scores.mean())\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8004562232393326\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.81381958, 0.79615385, 0.82307692, 0.79615385, 0.77307692])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = CountVectorizer(ngram_range=(1,3), max_features=10_000)  #yes you can use _'s in integers!\n",
    "clf = DecisionTreeClassifier()\n",
    "#tf-idf\n",
    "tfidf = TfidfTransformer()\n",
    "\n",
    "dt_pipe = Pipeline([('vect', count),('tfidf',tfidf),('clf', clf)])\n",
    "scores = cross_val_score(dt_pipe, X_train, y_train, cv=5, scoring = 'accuracy')\n",
    "print(scores.mean())\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, this was terrible, it's not getting any better. I have no idea!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your job.\n",
    "\n",
    "1. Create and try different decision trees, adaboost, and random forests. You can use other models if you want (scikit-learn models are easy to use!)\n",
    "2. Try adjusting the TFIDF parameters , n-gram parameters, and max_feature a parameter.\n",
    "3. Try different settings for your algorithms, max depth, number of estimators etc.\n",
    "4. Plot 1 Learning curve **and** 2 validation curves for your two most promising models.  Try to tune their parameters and get a higher accuracy. This means a total of 2 learning curves and 4 validation curves.\n",
    "\n",
    "Note that you can run gridsearch over the parameters in count-vecotrizer and tf-idf, it takes a bit of figuring out with the scikit learn documentation (how to pass the grid).\n",
    "When plotting your validation curves and using the pipeline you will need to pass the named step.\n",
    "Here is an example\n",
    "\n",
    "`pipe.named_steps` will printout all the names of my pipeline.\n",
    "Then once I know the name of the step in my pipeline (you set the names yourself when you create the pipeline), I can use the name and `__` to access it's parameters.\n",
    "For example if I named my classifier `clf` and it was a Decisiontree, if I wanted to adjust the `max_depth` on a validaiton curve I would run:\n",
    "\n",
    "`param_name='clf__max_depth'`\n",
    "This would access the `max_depth` attribute of my clf.\n",
    "\n",
    "Post your best models on the forums!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7969895172006496\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.82725528, 0.79038462, 0.80192308, 0.81538462, 0.75      ])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "count = CountVectorizer(max_features=20000)\n",
    "tfidf = TfidfTransformer()\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "dt_pipe = Pipeline([('vect', count), ('tfidf', tfidf), ('clf', clf)])\n",
    "scores = cross_val_score(dt_pipe, X_train, y_train, cv=5, scoring = 'accuracy')\n",
    "print(scores.mean())\n",
    "scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7916034253654215"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\"clf__max_depth\": (2,3,4,5,6,7,8,9), \"clf__min_samples_split\": (2,3,4,5,6,7,8,9),\"clf__min_samples_leaf\": (1,2,3,4,5,6,7), \n",
    "              \"vect__ngram_range\": ((1,1), (1,2), (1,3), (2,2))}\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(estimator=dt_pipe, param_distributions=param_grid, random_state=20)\n",
    "random_search.fit(X_train, y_train)\n",
    "random_search.best_score_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8008401003986417\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.81573896, 0.80192308, 0.80769231, 0.81538462, 0.76346154])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\"clf__max_depth\": (2,3,4,5,6,7,8,9), \"clf__min_samples_split\": (2,3,4,5,6,7,8,9),\"clf__min_samples_leaf\": (1,2,3,4,5,6,7), \n",
    "              \"vect__ngram_range\": ((1,1), (1,2), (1,3), (2,2))}\n",
    "grid = GridSearchCV(estimator=dt_pipe, param_grid=param_grid)\n",
    "scores = cross_val_score(dt_pipe, X_train, y_train, cv=5, scoring = 'accuracy')\n",
    "print(scores.mean())\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[84], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m plot_learning_curve(grid, X_train, y_train)\n",
      "File \u001b[0;32m~/Desktop/data-science-machine-learning-main/notebooks/plotting.py:87\u001b[0m, in \u001b[0;36mplot_learning_curve\u001b[0;34m(estimator, X, y, title, ylim, cv, n_jobs, train_sizes, scoring)\u001b[0m\n\u001b[1;32m     84\u001b[0m axes\u001b[38;5;241m.\u001b[39mset_xlabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining examples\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     85\u001b[0m axes\u001b[38;5;241m.\u001b[39mset_ylabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 87\u001b[0m train_sizes, train_scores, test_scores \u001b[38;5;241m=\u001b[39m learning_curve(\n\u001b[1;32m     88\u001b[0m     estimator, X, y, cv\u001b[38;5;241m=\u001b[39mcv, n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, train_sizes\u001b[38;5;241m=\u001b[39mtrain_sizes, scoring\u001b[38;5;241m=\u001b[39mscoring\n\u001b[1;32m     89\u001b[0m )\n\u001b[1;32m     90\u001b[0m train_scores_mean \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(train_scores, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     91\u001b[0m train_scores_std \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstd(train_scores, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/yes/envs/cn_ml_course/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/yes/envs/cn_ml_course/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:1954\u001b[0m, in \u001b[0;36mlearning_curve\u001b[0;34m(estimator, X, y, groups, train_sizes, cv, scoring, exploit_incremental_learning, n_jobs, pre_dispatch, verbose, shuffle, random_state, error_score, return_times, fit_params)\u001b[0m\n\u001b[1;32m   1951\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m n_train_samples \u001b[38;5;129;01min\u001b[39;00m train_sizes_abs:\n\u001b[1;32m   1952\u001b[0m         train_test_proportions\u001b[38;5;241m.\u001b[39mappend((train[:n_train_samples], test))\n\u001b[0;32m-> 1954\u001b[0m results \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[1;32m   1955\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m   1956\u001b[0m         clone(estimator),\n\u001b[1;32m   1957\u001b[0m         X,\n\u001b[1;32m   1958\u001b[0m         y,\n\u001b[1;32m   1959\u001b[0m         scorer\u001b[38;5;241m=\u001b[39mscorer,\n\u001b[1;32m   1960\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[1;32m   1961\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[1;32m   1962\u001b[0m         verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[1;32m   1963\u001b[0m         parameters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1964\u001b[0m         fit_params\u001b[38;5;241m=\u001b[39mfit_params,\n\u001b[1;32m   1965\u001b[0m         \u001b[38;5;66;03m# TODO(SLEP6): support score params here\u001b[39;00m\n\u001b[1;32m   1966\u001b[0m         score_params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1967\u001b[0m         return_train_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   1968\u001b[0m         error_score\u001b[38;5;241m=\u001b[39merror_score,\n\u001b[1;32m   1969\u001b[0m         return_times\u001b[38;5;241m=\u001b[39mreturn_times,\n\u001b[1;32m   1970\u001b[0m     )\n\u001b[1;32m   1971\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m train_test_proportions\n\u001b[1;32m   1972\u001b[0m )\n\u001b[1;32m   1973\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m   1974\u001b[0m results \u001b[38;5;241m=\u001b[39m _aggregate_score_dicts(results)\n",
      "File \u001b[0;32m~/yes/envs/cn_ml_course/lib/python3.12/site-packages/sklearn/utils/parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     73\u001b[0m )\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m~/yes/envs/cn_ml_course/lib/python3.12/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/yes/envs/cn_ml_course/lib/python3.12/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/yes/envs/cn_ml_course/lib/python3.12/site-packages/sklearn/utils/parallel.py:136\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/yes/envs/cn_ml_course/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:888\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    886\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    887\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 888\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    891\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    892\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/yes/envs/cn_ml_course/lib/python3.12/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/yes/envs/cn_ml_course/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1018\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m   1013\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m   1014\u001b[0m     )\n\u001b[1;32m   1016\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m-> 1018\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m   1022\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/yes/envs/cn_ml_course/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1572\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1570\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1571\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1572\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "File \u001b[0;32m~/yes/envs/cn_ml_course/lib/python3.12/site-packages/sklearn/model_selection/_search.py:964\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    956\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    957\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    958\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    959\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    960\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    961\u001b[0m         )\n\u001b[1;32m    962\u001b[0m     )\n\u001b[0;32m--> 964\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[1;32m    965\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    966\u001b[0m         clone(base_estimator),\n\u001b[1;32m    967\u001b[0m         X,\n\u001b[1;32m    968\u001b[0m         y,\n\u001b[1;32m    969\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[1;32m    970\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[1;32m    971\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[1;32m    972\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[1;32m    973\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[1;32m    974\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[1;32m    975\u001b[0m     )\n\u001b[1;32m    976\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[1;32m    977\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params),\n\u001b[1;32m    978\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39msplitter\u001b[38;5;241m.\u001b[39msplit)),\n\u001b[1;32m    979\u001b[0m     )\n\u001b[1;32m    980\u001b[0m )\n\u001b[1;32m    982\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    983\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    984\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    985\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    986\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    987\u001b[0m     )\n",
      "File \u001b[0;32m~/yes/envs/cn_ml_course/lib/python3.12/site-packages/sklearn/utils/parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     73\u001b[0m )\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m~/yes/envs/cn_ml_course/lib/python3.12/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/yes/envs/cn_ml_course/lib/python3.12/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/yes/envs/cn_ml_course/lib/python3.12/site-packages/sklearn/utils/parallel.py:136\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/yes/envs/cn_ml_course/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:888\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    886\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    887\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 888\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    891\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    892\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/yes/envs/cn_ml_course/lib/python3.12/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/yes/envs/cn_ml_course/lib/python3.12/site-packages/sklearn/pipeline.py:473\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    471\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    472\u001b[0m         last_step_params \u001b[38;5;241m=\u001b[39m routed_params[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[0;32m--> 473\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator\u001b[38;5;241m.\u001b[39mfit(Xt, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mlast_step_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    475\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/yes/envs/cn_ml_course/lib/python3.12/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/yes/envs/cn_ml_course/lib/python3.12/site-packages/sklearn/tree/_classes.py:1009\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    978\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    979\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    980\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[1;32m    981\u001b[0m \n\u001b[1;32m    982\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m   1007\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1009\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[1;32m   1010\u001b[0m         X,\n\u001b[1;32m   1011\u001b[0m         y,\n\u001b[1;32m   1012\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[1;32m   1013\u001b[0m         check_input\u001b[38;5;241m=\u001b[39mcheck_input,\n\u001b[1;32m   1014\u001b[0m     )\n\u001b[1;32m   1015\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/yes/envs/cn_ml_course/lib/python3.12/site-packages/sklearn/tree/_classes.py:472\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[0;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    462\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    463\u001b[0m         splitter,\n\u001b[1;32m    464\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    470\u001b[0m     )\n\u001b[0;32m--> 472\u001b[0m builder\u001b[38;5;241m.\u001b[39mbuild(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_, X, y, sample_weight, missing_values_in_feature_mask)\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    475\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_learning_curve(grid, X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cn_ml_course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
